{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porto Seguro Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Essential libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from Modules import utils as u\n",
    "from Modules import FeatureEngg as fe\n",
    "from Modules import ModelBasedFeatureEngg as mbf\n",
    "from Modules.Ensemble import Create_ensemble\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy import sparse as ssp\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "data_tr = pd.read_csv('train.csv')\n",
    "data_te = pd.read_csv('test.csv')\n",
    "id_tr = data_tr[\"id\"]\n",
    "id_te = data_te[\"id\"]\n",
    "y_tr = data_tr[\"target\"]\n",
    "data_tr = data_tr.drop([\"id\", \"target\"], axis = 1)\n",
    "data_te = data_te.drop(\"id\", axis = 1)\n",
    "    \n",
    "#Dropping 'calc' features\n",
    "#We are dropping these features as they do not show any significant\n",
    "#impact on the target variables.\n",
    "calc_features = []\n",
    "for f in data_tr.columns :\n",
    "    if 'calc' in f :\n",
    "        calc_features.append(f)\n",
    "data_tr = data_tr.drop(calc_features, axis = 1)\n",
    "data_te = data_te.drop(calc_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble Parameters\n",
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.01\n",
    "lgb_params['n_estimators'] = 900\n",
    "lgb_params['max_bin'] = 25\n",
    "lgb_params['subsample'] = 0.9\n",
    "lgb_params['subsample_freq'] = 25\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 600\n",
    "lgb_params['random_state'] = 6\n",
    "lgb_params['scale_pos_weight'] = 1\n",
    "lgb_params['min_child_weight'] = 0.001\n",
    "lgb_params['num_leaves'] = 31\n",
    "lgb_params['subsample_for_bin'] = 200000\n",
    "\n",
    "lgb_params1 = {}\n",
    "lgb_params1['learning_rate'] = 0.01\n",
    "lgb_params1['n_estimators'] = 700\n",
    "lgb_params1['max_bin'] = 15\n",
    "lgb_params1['subsample'] = 0.8\n",
    "lgb_params1['subsample_freq'] = 15\n",
    "lgb_params1['colsample_bytree'] = 0.9  \n",
    "lgb_params1['min_child_samples'] = 800\n",
    "lgb_params1['random_state'] = 6\n",
    "lgb_params1['scale_pos_weight'] = 3\n",
    "lgb_params1['min_child_weight'] = 0.001\n",
    "lgb_params1['num_leaves'] = 25\n",
    "lgb_params1['subsample_for_bin'] = 200000\n",
    "\n",
    "lgb_params2 = {}\n",
    "lgb_params2['learning_rate'] = 0.02\n",
    "lgb_params2['n_estimators'] = 900\n",
    "lgb_params2['max_bin'] = 20\n",
    "lgb_params2['subsample'] = 0.8\n",
    "lgb_params2['subsample_freq'] = 10\n",
    "lgb_params2['colsample_bytree'] = 0.8   \n",
    "lgb_params2['min_child_samples'] = 600\n",
    "lgb_params2['random_state'] = 6\n",
    "lgb_params2['scale_pos_weight'] = 3\n",
    "lgb_params1['min_child_weight'] = 0.001\n",
    "lgb_params2['num_leaves'] = 25\n",
    "lgb_params2['subsample_for_bin'] = 200000\n",
    "\n",
    "\n",
    "lgb_model = LGBMClassifier(**lgb_params)\n",
    "lgb_model1 = LGBMClassifier(**lgb_params1)\n",
    "lgb_model2 = LGBMClassifier(**lgb_params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(data_tr, data_te, y_tr) :\n",
    "    '''\n",
    "    -> This function includes entire pipeline, from data preprocessing to making final predictions.\n",
    "    -> It takes raw data as input and returns final predictions for them.\n",
    "    '''\n",
    "    #Performing all the feature engineering tasks and getting the final features\n",
    "    fe.feature_engineering(data_tr, data_te, y_tr)\n",
    "    #Generating model based features\n",
    "    #This can take upto 24hrs\n",
    "    mbf.ModelBasedFeatures(data_tr, data_te, y_tr)\n",
    "    #-------------------------------------------------------------------------------\n",
    "    #Loading featured engineered and model based features\n",
    "    print('Loading Train Data...')\n",
    "    X = pd.read_csv('final_train.csv')\n",
    "    print('Loading Test Data...')\n",
    "    X_te = pd.read_csv('final_test.csv')\n",
    "    print('Loading Labels...')\n",
    "    y = pd.read_csv('labels.csv')\n",
    "    train_id = X['id']\n",
    "    test_id = X_te['id']\n",
    "    X = X.drop(['Unnamed: 0', 'id'], axis = 1)\n",
    "    X_te = X_te.drop(['Unnamed: 0', 'id'], axis = 1)\n",
    "    y = y.drop(['Unnamed: 0'], axis = 1)\n",
    "    #-------------------------------------------------------------------------------\n",
    "    car_tr_fea, car_te_fea = pickle.load(open(\"car_features.pk\",'rb'), encoding='iso-8859-1')\n",
    "    ind_tr_fea, ind_te_fea = pickle.load(open(\"ind_features.pk\",'rb'), encoding='iso-8859-1')\n",
    "    reg_tr_fea, reg_te_fea = pickle.load(open(\"reg_features.pk\",'rb'), encoding='iso-8859-1')\n",
    "    #-------------------------------------------------------------------------------\n",
    "    fea_tr = np.concatenate((car_tr_fea, ind_tr_fea, reg_tr_fea), axis = 1)\n",
    "    fea_te = np.concatenate((car_te_fea, ind_te_fea, reg_te_fea), axis = 1)\n",
    "    #-------------------------------------------------------------------------------\n",
    "    fea_tr_df = pd.DataFrame(fea_tr)\n",
    "    fea_te_df = pd.DataFrame(fea_te)\n",
    "    #-------------------------------------------------------------------------------\n",
    "    X = pd.concat(objs=[X, fea_tr_df], axis = 1)\n",
    "    X_te = pd.concat(objs=[X_te, fea_te_df], axis = 1)\n",
    "    #-------------------------------------------------------------------------------\n",
    "    lgb_stack = Create_ensemble(n_splits = 5, base_models = [lgb_model, lgb_model1, lgb_model2])        \n",
    "    X = X\n",
    "    Y = y\n",
    "    T = X_te\n",
    "    lgb_train_pred, lgb_test_pred = lgb_stack.predict(X, Y, T)\n",
    "    #-------------------------------------------------------------------------------\n",
    "    #The predictions for the inputs will be stored in Ensemble.csv\n",
    "    sub = pd.DataFrame()\n",
    "    sub['id'] = test_id\n",
    "    sub['target'] = lgb_test_pred.mean(axis=1)\n",
    "    sub.to_csv('Ensemble.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2(data_tr, data_te, y_tr) :\n",
    "    final_fun_1(data_tr, data_te, y_tr)\n",
    "    #Printing final Gini Score\n",
    "    y_pred = pd.read_csv('Ensemble.csv')\n",
    "    print( \"\\nFinal Gini : {}\".format(u.eval_gini(y_tr, S_train[:,i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
